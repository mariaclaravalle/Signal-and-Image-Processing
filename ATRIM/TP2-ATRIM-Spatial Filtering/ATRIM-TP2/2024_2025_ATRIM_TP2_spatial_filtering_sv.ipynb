{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHdYvgrqkBgW"
   },
   "source": [
    "# TP2 - Spatial Filtering\n",
    "ATRIM - Option Datasim\n",
    "\n",
    "Ecole Centrale Nantes\n",
    "\n",
    "Diana Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W46TsdtykBgf"
   },
   "source": [
    "Participants: (FILL IN YOUR NAMES AND LASTNAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSnKk0CwkBgg"
   },
   "source": [
    "# GOAL\n",
    "\n",
    "In this lab we will practice the general principles of linear spatial filtering for 2D images:\n",
    "- based on the convolution operation\n",
    "- and applied with different filters to solve different tasks (denoising, highboost sharpening, border extraction)\n",
    "\n",
    "Then, we will break some of the linear filtering assumptions:\n",
    "- to find patterns in an image (Waldo/Charlie) with correlation,\n",
    "- to filter preserving borders,\n",
    "- to find corners in an image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq1OpVfzkBgh"
   },
   "source": [
    "# 0. Preparation\n",
    "\n",
    "* Define the path to the images only once. Then, use the given path for the images\n",
    "\n",
    "* Handling several large images can create large memory demands. In order to avoid large size files that slow processing, you can:\n",
    "  - reuse the image variable names\n",
    "  - clear large variables with the command\n",
    "   ```reset_selective name_variable```\n",
    "  - If required resize the images while debugging (e.g. to 100x100)\n",
    "  - Before submiting your jupyter notebook empty the outputs first: go to the Kernel menu, restart and clear output.\n",
    "\n",
    "  - If you get some warnings \"IOPub data rate exceeded\" launch your notebook with\n",
    "\n",
    "  ```jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIj3veQ1kBgi"
   },
   "source": [
    "### 0.1 Importing the required modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rfcG-AykBgl"
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.transform import resize, rescale\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBEUAiOTkBgo"
   },
   "source": [
    "### 0.2 Define the main image folder\n",
    "Make sure the subsequent parts of this notebook refer to this definition IMDIR. **When evaluating your notebook I should only need to change the path here** to run the entire notebook and find all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qC3Z1ioAkBgp"
   },
   "outputs": [],
   "source": [
    "IMDIR = \"./images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrLXjGg87PZ6"
   },
   "outputs": [],
   "source": [
    "#If using Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#IMDIR = \"/content/drive/MyDrive/Colab Notebooks/2022-2023 Image Processing/02-spatial-filtering /images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMCOO_GOkBgq"
   },
   "source": [
    "### 0.3 Read and display the images\n",
    "Check that you can read and display all the provided images. **Do not include this cell**, neither the code nor its ouput in the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqH0916QkBgq"
   },
   "outputs": [],
   "source": [
    "width=20\n",
    "height=10\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "fig=plt.figure()\n",
    "\n",
    "im_counter = 1\n",
    "for root, dirnames, filenames in os.walk(IMDIR):\n",
    "    #print(dirnames)\n",
    "    for filename in filenames:\n",
    "        f = os.path.join(root, filename)\n",
    "\n",
    "        #filter only image files with the following format\n",
    "        if f.endswith(('.png', '.jpg', '.jpeg','.JPG', '.tif', '.gif')):\n",
    "\n",
    "            # print the paths to current filename if nothing is being found\n",
    "            #print(filename)\n",
    "\n",
    "            # read the image\n",
    "            im = io.imread(f,as_gray=True)\n",
    "            im = resize(im,(100,100),mode='constant')\n",
    "\n",
    "            # display it\n",
    "            if im_counter >= 25:\n",
    "                break;\n",
    "\n",
    "            plt.subplot(5,5,im_counter)\n",
    "            plt.imshow(im, cmap='gray')\n",
    "            plt.title(filename)\n",
    "            plt.axis('off')\n",
    "            im_counter +=1\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGHXNHPbkBgu"
   },
   "source": [
    "\n",
    "# 1 Linear spatial filtering with convolution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WudCbpEEfLZ8"
   },
   "source": [
    "## 1.1. Mean Kernel Example\n",
    "The following ``meanKernel'' function creates a smoothing kernel, which can be used with scipy's ``` ndimage.convolve(im,kernel) ```\n",
    "convolution function to blur an image.\n",
    "\n",
    "Run the following cells to display different versions of the kernel and the application of a mean_kernel on an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heNl9x2XfLC5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lV6D--5zkBgu"
   },
   "outputs": [],
   "source": [
    "def meanKernel(hs):\n",
    "    #hs defines the size of the kernel\n",
    "    #hs is the integer half size of the kernel\n",
    "    #creates an square filter with each side of length 2*hs+1\n",
    "    kernel = np.zeros((hs*2+1,hs*2+1))\n",
    "    kernel += 1/(hs*2+1)**2\n",
    "    return kernel\n",
    "\n",
    "#Display properties\n",
    "width=12\n",
    "height=3\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "#creating and showing three mean kernels of different sizes\n",
    "k = 1\n",
    "for hs in [1,3,11]:\n",
    "    plt.subplot(1,3,k)\n",
    "    kernel = meanKernel(hs)\n",
    "    plt.imshow(kernel, vmin=0, vmax=0.2)\n",
    "    plt.title('Mean')\n",
    "    plt.colorbar()\n",
    "    k+=1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJyw_3eVkBgw"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display properties\n",
    "width=10\n",
    "height=5\n",
    "\n",
    "#Filter parameters\n",
    "hs = 3\n",
    "sigma = 2\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Define filter and convolve\n",
    "kernel = meanKernel(hs)\n",
    "im_filtered_scipy = ndimage.convolve(im,kernel)\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# Display the filtered image\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Mean scipy conv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tcu-dvnkBgy"
   },
   "source": [
    "## 1.2. Gaussian Kernel\n",
    "Following the above example, create, display and apply several (at least 3) Gaussian kernels with varying window size and standard deviation.\n",
    "\n",
    "**Question: ** what is the sum of the kernel elements in each case?, why is this necessary?\n",
    "\n",
    "```Hints```:\n",
    "- use the 'None' or 'Nearest' interpolation options of imshow to display the kernel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM1RhYzDkBg0"
   },
   "outputs": [],
   "source": [
    "#both versions work, pick the one you are more confortable with\n",
    "\n",
    "def gaussianKernel(hs,sigma, normalize=True): #half window size and Gaussian sigma\n",
    "    # creating an empty kernel\n",
    "    kernel = np.zeros((hs*2+1,hs*2+1))\n",
    "    ax = np.arange(-hs, hs+1)\n",
    "\n",
    "    # filling the kernel elements\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "\n",
    "    ### FILL BEGIN\n",
    "    kernel = np.exp( ) #FILL IN\n",
    "    ### FILL END\n",
    "\n",
    "    # normalize and return\n",
    "    if normalize:\n",
    "        kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def gaussianLambdaKernel(size,sigma, normalize=True): #full window size and Gaussian sigma\n",
    "\n",
    "    ### FILL BEGIN\n",
    "    kernel = np.fromfunction(lambda x, y: math.e ** ( FILL IN ), (size, size))\n",
    "    ### FILL END\n",
    "\n",
    "    if normalize:\n",
    "        kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihLUz_IJkBg3"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display size\n",
    "width=10\n",
    "height=10\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(3, 3))\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# Define filter parameters\n",
    "filter_sizes=[1,3,5]\n",
    "sigma_values=[0.1,1,2]\n",
    "\n",
    "# Display filters as images\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "#FILL IN\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Convolve the image with the filter and display the filtered image\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "#FILL IN\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F6Rdq0HkBg3"
   },
   "source": [
    "## 1.3 Filtering with your own Convolution\n",
    "**a)** Repeat the smoothing above with your own implementation of the ```convolution``` function. The function should receive as input an image and a filter kernel (matrix of weights) and return the filtered image. Compare your results with those from the scikit in-built function.\n",
    "\n",
    "**b)** Apply a Gaussian filter of kernel size 7x7 (hs=3) and sigma 2 display side by side the results of your convolution vs. those of the in-built function to check your implementation is correct. Clearly state on the title of the image which version of the convolution function is being used.\n",
    "\n",
    "**c)** **Write down your findings**, notably the reasons for any possible difference with the in-built implementation.\n",
    "\n",
    "**d)** Why and how can the convolution can be written as a matrix multiplication? why is it interesting?\n",
    "```Hint```:  see http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wM6ZoLBwkBg4"
   },
   "outputs": [],
   "source": [
    "def myConvolution(imsource,kernel):\n",
    "\n",
    "    # Find image and kernel sizes\n",
    "    im_shape = imsource.shape\n",
    "    imh,imw = im_shape[0], im_shape[1]\n",
    "    kh,kw = kernel.shape\n",
    "    delta_h=int((kh-1)/2)\n",
    "    delta_w=int((kw-1)/2)\n",
    "\n",
    "    # Image padding\n",
    "    imPadded = np.zeros((imh+2*delta_h,imw+2*delta_w))\n",
    "    imPadded[delta_h:imh+delta_h,delta_w:imw+delta_w]=imsource\n",
    "\n",
    "    # Create an empty image to store the result\n",
    "    imDest = np.zeros((imh,imw))\n",
    "\n",
    "    #BEGIN FILL IN\n",
    "    for i in range(imh):\n",
    "        for j in range(imw):\n",
    "\n",
    "\n",
    "    #END FILL IN\n",
    "    return imDest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1Pe5wmWpIiu"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display properties\n",
    "width=10\n",
    "height=10\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# Define filter parameters\n",
    "hs=3\n",
    "sigma=2\n",
    "kernel = gaussianKernel(hs,sigma)\n",
    "\n",
    "# Convolve and display the filtered image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-jZqRhJrhVG"
   },
   "source": [
    "## 1.4 Derivative filters\n",
    "\n",
    "Define the required kernel function and convolve them with the *AscentB* or *Moon* images in the ``enhance`` folder to obtain\n",
    "*  the gradient image in the horizontal direction\n",
    "*  the gradient image in the vertical direction\n",
    "*  the Laplacian of the image\n",
    "*  the sharpened image after addition of the Laplacian \"details\" (and normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjOUmq4gtNd-"
   },
   "outputs": [],
   "source": [
    "def sobel_x():\n",
    "    kernel = np.zeros((3,3))\n",
    "\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def sobel_y():\n",
    "    kernel = np.zeros((3,3))\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def laplacian():\n",
    "    kernel = np.ones((3,3))\n",
    "\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def normalize(im):\n",
    "    im = (im-im.min())/(im.max()-im.min())\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Jzx6wYJvFR2"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"moon-blurred.tif\")\n",
    "#f = os.path.join(IMDIR, \"ascentB.png\")\n",
    "\n",
    "#Display properties\n",
    "width=15\n",
    "height=5\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "#im = resize(im,(100,100))\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# Convolve and display the filtered and the enhanced image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgQwyWvDyvwc"
   },
   "source": [
    "# 2 Non linear filtering\n",
    "\n",
    "Choose one among the two following tasks: either finding Charlie or bilateral filter.\n",
    "\n",
    "Hint: USE A DIFFERENT NOTEBOOK FOR WALDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbLNobOdzOJO"
   },
   "source": [
    "## 2.1 Correlation: Finding Charlie\n",
    "\n",
    "Use patch-wise Normalized Cross Correlation (NCC) to automatically find Waldo (Charlie) in an image. To this end, look for the template image (``charlie-template``) inside ``marche-crop`` or the ``marche`` images. As the process can be long start with the cropped version, you might also find it useful to **create a separate notebook for this task only** as it is memory consuming. Evaluate the NCC expression from the slides (described in the non-local means advance filtering) to compare the template with every location in the target image, store the results and retrieve the location with the highest NCC score. Draw this location on the target image.\n",
    "\n",
    "**Describe the process assumptions and limitations**\n",
    "\n",
    "Hint: Start from your convolution operation but apply locally normalized correlation at each pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTsP-_KBzoHo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2MoCuRPkBg8"
   },
   "source": [
    "## 2.2 Bilateral Filter  \n",
    "\n",
    "**a)** Implement your own version of the ``bilateral`` filter and compare its results vs. scikit ``denoise_bilateral`` function.\n",
    "\n",
    "**b)** Compare and comment the bilateral results versus the mean and gaussian filter for the ``zebra`` group of images of the ``bilateral`` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FH7TEET0kBg7"
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "#im_filtered_scipy = denoise_bilateral(im, win_size=hs*2+1, sigma_color=0.05, sigma_spatial=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT0P0xr_kBg6"
   },
   "source": [
    "# 3. Harris corners\n",
    "\n",
    "3.1 Implement the Harris corner detector.\n",
    "\n",
    "**a)** Compute and show the gradient images ($Ix$ and $Iy$)  as well as their outer products ($IxIx$, $IxIy$, $I_yI_y$) for the *pixel-pancho* images in the ``corners`` folder\n",
    "\n",
    "**b)** From the previous result, compute the **weighted** and **aggregated** gradient products. *Hints:*\n",
    "- To weigh, convolve the gradient products ($IxIx$, $IxIy$, and $I_yI_y$) each with a Gaussian filter.\n",
    "- To aggregate, sum up at each pixel location the values of the weighed gradient products over a window ($(x,y)\\in\\mathcal{N}_{x_0,y_0}$).\n",
    "\n",
    "**c)** From the previous result,\n",
    "- build the structure tensor or Harris matrix $M$ for each pixel $(x_0,y_0)$ in the image.\n",
    "- and compute the cornerness criteria based on its eigenvalues. Display the result as a *score map* image.\n",
    "Hint: Compute the cornerness implicitly (using the fact that determinant of a 2x2 matrix is the product of the matrix eigenvalues and the trace its sum)\n",
    "\n",
    "**d)** Define a threshold on the score map, and display the detected corners on top of the original images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_cns4WykBg8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3P3B8hS6ooL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jZL5U16NVWx"
   },
   "source": [
    "3.2 **Questions**\n",
    "**a)** Why is the Gaussian filtering important?\n",
    "\n",
    "**b)** Explain how steps 3.1 b) and 3.2 c) are related to the autocorrelation\n",
    "\n",
    "**c)** What do the eigenvalues of the structure tensor matrix represent?\n",
    "\n",
    "**d)** What is the influence of the k parameter?\n",
    "\n",
    "**e)** What other parameters determine the result?\n",
    "\n",
    "**f)** Observing the results for the two images, why is it interesting to extract the corners?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0LE7cwRLoBn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2N6oVDyLpww"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
