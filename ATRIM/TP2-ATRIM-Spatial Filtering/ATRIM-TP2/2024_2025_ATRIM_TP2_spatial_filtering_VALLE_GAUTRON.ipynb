{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHdYvgrqkBgW"
   },
   "source": [
    "# TP2 - Spatial Filtering\n",
    "ATRIM - Option Datasim\n",
    "\n",
    "Ecole Centrale Nantes\n",
    "\n",
    "Diana Mateus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5753fK6-8H1s"
   },
   "source": [
    "Edouard GAUTRON et Maria clara VALLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dans ce rapport, nous explorerons les principes du filtrage spatial linéaire appliqué aux images 2D. Nous utiliserons différents types de filtres (kernel) et examinerons leurs capacités à accomplir diverses opérations sur des images en ajustant leurs paramètres. Cette première partie permettra de mieux comprendre comment ces filtres modifient le contenu visuel et leur utilité dans des tâches comme le lissage, le renforcement des détails, ou encore la détection de contours.\n",
    "\n",
    "Dans une deuxième phase, nous implémenterons des algorithmes de filtrage plus avancés afin de développer des méthodes capables de reconnaître des motifs spécifiques dans les images tout en préservant les contours et les détails essentiels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2894,
     "status": "ok",
     "timestamp": 1728405194949,
     "user": {
      "displayName": "Maria Clara Castro Valle",
      "userId": "04999322324447278425"
     },
     "user_tz": -120
    },
    "id": "3rfcG-AykBgl"
   },
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.transform import resize, rescale\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1728406096365,
     "user": {
      "displayName": "Maria Clara Castro Valle",
      "userId": "04999322324447278425"
     },
     "user_tz": -120
    },
    "id": "qC3Z1ioAkBgp"
   },
   "outputs": [],
   "source": [
    "IMDIR = r\"C:\\Users\\maria\\DataSim\\ATRIM\\TP2-ATRIM-Spatial Filtering\\ATRIM-TP2\\images\" #nous indiquon le chemin pour acceder aux images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGHXNHPbkBgu"
   },
   "source": [
    "# 1 Linear spatial filtering with convolution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGHXNHPbkBgu"
   },
   "source": [
    "Nous commençons par exécuter l'exemple \"meanKernel\" qui crée un kernel flou.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lV6D--5zkBgu",
    "outputId": "17e7624c-fc28-463c-eaf8-c183c91328fe"
   },
   "outputs": [],
   "source": [
    "def meanKernel(hs):\n",
    "    #hs on defini la taille du kernel\n",
    "    #hs est un entier de la moitier de la taille du kernel\n",
    "    #on créer un filtre carré de taille 2*hs+1\n",
    "    kernel = np.zeros((hs*2+1,hs*2+1))\n",
    "    kernel += 1/(hs*2+1)**2\n",
    "    return kernel\n",
    "\n",
    "#on affiche les propriétés\n",
    "width=12\n",
    "height=3\n",
    "plt.rcParams['figure.figsize'] = [width, height]\n",
    "\n",
    "#on crée et affiche trois differents kernels\n",
    "k = 1\n",
    "for hs in [1,3,11]:\n",
    "    plt.subplot(1,3,k)\n",
    "    kernel = meanKernel(hs)\n",
    "    plt.imshow(kernel, vmin=0, vmax=0.2)\n",
    "    plt.title(f'Mean, hs ={hs}')\n",
    "    plt.colorbar()\n",
    "    k+=1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous le convoluons avec une image en utilisant la fonction convolve. Avec ça, on va observer l'effet que chaque filtre moyenne a sur les images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJyw_3eVkBgw",
    "outputId": "559c59ca-999a-4dbb-eb1f-9b089bf2f588"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display properties\n",
    "width=10\n",
    "height=5\n",
    "\n",
    "#Filter parameters\n",
    "hs = 3 #change le niveau de blur\n",
    "sigma = 2\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Define filter and convolve\n",
    "kernel = meanKernel(hs)\n",
    "im_filtered_scipy = ndimage.convolve(im,kernel)\n",
    "\n",
    "\n",
    "# on affiche l'image originale\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# affichage de l'image resultante\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Mean scipy conv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJyw_3eVkBgw",
    "outputId": "559c59ca-999a-4dbb-eb1f-9b089bf2f588"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display properties\n",
    "width=10\n",
    "height=5\n",
    "\n",
    "#Filter parameters\n",
    "hs = 3 #change le niveau de blur\n",
    "sigma = 2\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Define filter and convolve\n",
    "kernel = meanKernel(hs)\n",
    "im_filtered_scipy = ndimage.convolve(im,kernel)\n",
    "\n",
    "# on affiche l'image originale\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# affichage de l'image resultante\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Mean scipy conv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que quand on augmente la taille du filtre (hs), l'image devient plus flou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tcu-dvnkBgy"
   },
   "source": [
    "## 1.2. Gaussian Kernel\n",
    "Ici, nous créons des noyaux gaussiens de tailles et d'écart-types variés, puis nous les appliquons à l'image \"grass.png\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM1RhYzDkBg0"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gaussianKernel(hs,sigma, normalize=True): \n",
    "    # pour crée le kernel on crée une matrice de zero de la meme taille\n",
    "    kernel = np.zeros((hs*2+1,hs*2+1))\n",
    "    ax = np.arange(-hs, hs+1)\n",
    "\n",
    "    # on crée le kernel\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "\n",
    "    #on definit le kernel en s'appuyant sur le model du cours;\n",
    "    kernel = np.exp(-(xx**2+yy**2)/(2*sigma**2))/(2*np.pi*sigma**2) \n",
    "    \n",
    "\n",
    "    # on normalise et retourne\n",
    "    if normalize:\n",
    "        kernel = kernel / np.sum(kernel)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihLUz_IJkBg3",
    "outputId": "cd3271b4-a2dd-41db-eb28-50b4fab06aa5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display size\n",
    "width=10\n",
    "height=10\n",
    "k = 1\n",
    "iter_conv = 1\n",
    "filters = []\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(3, 3))\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# Don definit les differents parametres pour les differents filtres\n",
    "filter_sizes=[1,3,5]\n",
    "sigma_values=[0.1,1,2]\n",
    "\n",
    "# dans un premier temps on affiche les filtres\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "####### debut de notre code\n",
    "for hs in filter_sizes:\n",
    "    for sigma in sigma_values:\n",
    "        filter = gaussianKernel(hs,sigma, normalize=True)\n",
    "        plt.subplot(3,6,2*k-1)\n",
    "        #display the filter\n",
    "        plt.imshow(filter, cmap = 'gray')\n",
    "        plt.title(f\"filtre, hs: {hs}, sigma : {sigma}\")\n",
    "        print(f'sum des element kernel avec hs = {hs} et sigma = {sigma} : {np.sum(filter)}')\n",
    "\n",
    "        plt.subplot(3,6,2*k)\n",
    "        # Convolve and display the filtered image\n",
    "        conv = ndimage.convolve(im,filter)#on fait la convolution pour appliquer les filtres aux images\n",
    "        plt.imshow(conv, cmap = 'gray')\n",
    "        plt.title(\"image filtrée\")\n",
    "        \n",
    "        k += 1\n",
    "        filters.append(filter)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Convolve the image with the filter and display the filtered image\n",
    "#fig=plt.figure(figsize=(width, height))\n",
    "\n",
    "#for kernel in filters:\n",
    "    #print(kernel)\n",
    "    #print('prochaine')\n",
    "    #print(np.sum(kernel[::2]))\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihLUz_IJkBg3",
    "outputId": "cd3271b4-a2dd-41db-eb28-50b4fab06aa5"
   },
   "source": [
    " Ainsi, on peut observer l'affichage des trois filtres, qui n'ont pas tous la meme taille ni le meme sigma, \n",
    " on s'attend donc a des resultats differents.\n",
    " On observe que plus la taille du filtre est grande et le sigma grand plus l'image est floue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red' size = '5'> Answer to question </font>On voit bien que la somme des éléments du noyau est égale à 1, ce qui est nécessaire car cela permet de conserver la luminosité de l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F6Rdq0HkBg3"
   },
   "source": [
    "## 1.3 Filtering with your own Convolution\n",
    "\n",
    "Nous avons répété le lissage effectué précédemment en implémentant notre propre fonction de convolution. Cette fonction prend en entrée une image et un noyau de filtre (matrice de poids) pour renvoyer l'image filtrée. Après avoir appliqué cette méthode sur les mêmes images que celles utilisées avec la fonction intégrée de Scikit-learn, nous avons comparé les résultats. \n",
    "\n",
    "<font color='red' size = '5'> Answer to question c) </font>** **Write down your findings**, notably the reasons for any possible difference with the in-built implementation.\n",
    "\n",
    "Les images obtenues avec notre implémentation étaient très similaires à celles produites par Scikit-learn, confirmant ainsi la validité de notre approche. Toutefois, on a regarde la difference entre l'image filtré a partir de notre convolution et cela déjà implementé. Pour cela on applique les deux methode et on soustrait les deux matrices obtenues, pour mettre en valeure des differences\n",
    "Apres avoir fait cette difference on remarque une image noir ce qui montre qu'il n'y a pas de difference, a part sur les bords \n",
    "cela provient probablement de impadded\n",
    "\n",
    "<font color='red' size = '5'> Answer to question d) </font> Why and how can the convolution can be written as a matrix multiplication? why is it interesting?\n",
    "\n",
    "on remarque que la convolution effectue des opperation tres proche de celle de a multiplication de matrice juste on ne multipli et addition pas les elements dans le meme orde il suffit alors de modifier les matrices pour les quelles on faisait la convolution et ainsi une simple multiplication de matrice suffira. Ce procedé est moins couteu ce qui le rend plus interessant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wM6ZoLBwkBg4"
   },
   "outputs": [],
   "source": [
    "def myConvolution(imsource,kernel):\n",
    "\n",
    "    # Find image and kernel sizes\n",
    "    im_shape = imsource.shape\n",
    "    imh,imw = im_shape[0], im_shape[1]\n",
    "    kh,kw = kernel.shape\n",
    "    print(kh)\n",
    "    delta_h=int((kh-1)/2)\n",
    "    delta_w=int((kw-1)/2)\n",
    "\n",
    "    print(delta_h)\n",
    "    # on elargie l'image avec des zeros autour car le filtre a une certaine taille qui depasse donc de la matrice si il passe le long des bords\n",
    "    imPadded = np.zeros((imh+2*delta_h,imw+2*delta_w))\n",
    "    imPadded[delta_h:imh+delta_h,delta_w:imw+delta_w] = imsource\n",
    "    \n",
    "\n",
    "    # Create an empty image to store the result\n",
    "    imDest = np.zeros((imh,imw))\n",
    "\n",
    "    \n",
    "    for i in range(imh):\n",
    "        for j in range(imw): # on parcour la matrice par les lignes et colones\n",
    "\n",
    "####### On a essayé une premiere methode qui fonctionne mais pas parfaitement on a choisit d'en faire une deuxieme \n",
    "             #for u in range(kh):\n",
    "             #   for v in range(kw):\n",
    "\n",
    "                   # imDest[i,j] += kernel[u , v]*imPadded[i +2*delta_h- u, j +2*delta_h- v]\n",
    "\n",
    "            \n",
    "###### deuxieme methode\n",
    "            imPatch = imPadded[i:i+kh, j:j+kw]\n",
    "            imDest[i,j] = np.sum(imPatch*np.flip(kernel))\n",
    "\n",
    "\n",
    "    #END FILL IN\n",
    "    return imDest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1Pe5wmWpIiu",
    "outputId": "d030f910-d22d-4390-d272-9c7577df7e00"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"grass.jpg\")\n",
    "\n",
    "#Display properties\n",
    "width=10\n",
    "height=10\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = resize(im,(100,100))\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "# Define filter parameters\n",
    "hs = 11\n",
    "sigma = 2\n",
    "kernel = gaussianKernel(hs,sigma)\n",
    "\n",
    "##### debut de notre code\n",
    "\n",
    "# Convolve and display the filtered image\n",
    "conv = myConvolution(im,kernel)\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(conv, cmap = 'gray')\n",
    "plt.title('My_conv')\n",
    "\n",
    "conv_2 = ndimage.convolve(im,kernel)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(conv, cmap = 'gray')\n",
    "plt.title('Convole')\n",
    "\n",
    "dif = conv_2 - conv\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(dif, cmap = 'gray')\n",
    "plt.title('Convole')\n",
    "\n",
    "#### fin de notre code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Maintenant on va comparer notre solution pour appliquer le filtre avec la convolution\n",
    " pour cela on applique les deux methode et on soustrait les deux matrices obtenues, pour mettre en valeure des differences\n",
    " Apres avoir fait cette difference on remarque une image noir ce qui montre qu'il n'y a pas de difference, a part sur les bords \n",
    " cela provient probablement de impadded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-jZqRhJrhVG"
   },
   "source": [
    "## On etudie les filtres derivés\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a défini la fonction de noyau nécessaire et l'a convoluée avec les images AscentB ou Moon dans le dossier enhance pour obtenir :\n",
    "\n",
    "l'image du gradient dans la direction horizontale,\n",
    "l'image du gradient dans la direction verticale,\n",
    "le Laplacien de l'image,\n",
    "l'image améliorée après l'ajout des \"détails\" du Laplacien (et la normalisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjOUmq4gtNd-"
   },
   "outputs": [],
   "source": [
    "# Pour se faire on créer differents kernels associé a chaque opération\n",
    "\n",
    "def sobel_x():\n",
    "    kernel = np.zeros((3,3))\n",
    "# on crée le filtre    \n",
    "    kernel = [[1, 0, -1],\n",
    "             [2, 0, -2],\n",
    "             [1 ,0, -1]]\n",
    "    return kernel\n",
    "\n",
    "def sobel_y():\n",
    "    kernel = np.zeros((3,3))\n",
    "# on crée le filtre\n",
    "    kernel = [[1, 2, 1],\n",
    "             [0, 0, 0],\n",
    "             [-1 ,-2, -1]]\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def laplacian():\n",
    "# on crée le filtre\n",
    "    kernel = [[0, 1, 0],\n",
    "             [1, -4, 1],\n",
    "             [0, 1, 0]]\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def normalize(im):\n",
    "    im = (im-im.min())/(im.max()-im.min())\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Jzx6wYJvFR2"
   },
   "outputs": [],
   "source": [
    "f = os.path.join(IMDIR, \"enhance/moon-blurred.tif\")\n",
    "#f = os.path.join(IMDIR, \"ascentB.png\")\n",
    "\n",
    "#Display properties\n",
    "width=15\n",
    "height=5\n",
    "\n",
    "# Read and preprocess image\n",
    "im = io.imread(f, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = normalize(im)\n",
    "#im = resize(im,(100,100))\n",
    "\n",
    "# Display the original image\n",
    "fig=plt.figure(figsize=(width, height))\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('Original')\n",
    "\n",
    "##### debut code alouté \n",
    "# Convolve and display the filtered and the enhanced image\n",
    "im_filtered_x =  ndimage.convolve(im,sobel_x())\n",
    "im_filtered_x =  np.clip(im_filtered_x, 0, 1) #sature l'image entre 0 et 1\n",
    "im_filtered_y =  ndimage.convolve(im,sobel_y())\n",
    "im_filtered_y =  np.clip(im_filtered_y, 0, 1)\n",
    "im_filtered_laplace =  ndimage.convolve(im, laplacian())\n",
    "im_filtered_laplace  =  np.clip(im_filtered_laplace, 0, 1)\n",
    "\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(im_filtered_x, cmap = 'gray')\n",
    "plt.title('gradx')\n",
    "plt.subplot(1,5,3)\n",
    "plt.imshow(im_filtered_y, cmap = 'gray')\n",
    "plt.title('grady')\n",
    "\n",
    "norme = np.sqrt(im_filtered_x**2+im_filtered_y**2)\n",
    "plt.subplot(1,5,4)\n",
    "plt.imshow(norme, cmap = 'gray')\n",
    "plt.title('magnitude')\n",
    "\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(im_filtered_laplace, cmap = 'gray')\n",
    "plt.title('laplace')\n",
    "##### fin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2MoCuRPkBg8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    " On observe differents resultatts selon les filtres utilisés notaments selon le sens de la derivé qui ne mets pas en valeur les memes particumarités \n",
    " de la lune l'un les bords et l'autre les crateres, on remarque que pour le cas de la lune le laplacien efface les crateres et nelaisse place qu'au contour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgQwyWvDyvwc"
   },
   "source": [
    "# 2 Non linear filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbLNobOdzOJO"
   },
   "source": [
    "## 2.1 Correlation: Finding Charlie\n",
    "\n",
    "On a utilisé la corrélation croisée normalisée (NCC) par blocs pour trouver automatiquement Waldo (Charlie) dans une image. Pour cela, on a recherché l’image modèle (charlie-template) dans les images marche-crop. Il a également été utile de créer un notebook séparé (Finding Charlie) pour cette tâche, car elle consomme beaucoup de mémoire.\n",
    "\n",
    "On a évalué l'expression du NCC issue des diapositives (décrite dans le filtrage avancé non-local means) pour comparer l'image modèle à chaque position dans l'image cible. Les résultats ont été stockés, et on a récupéré l'emplacement ayant obtenu le score NCC le plus élevé. Enfin, on a tracé cet emplacement sur l'image cible.\n",
    "\n",
    "<font color='red' size = '5'> Answer to question </font>On vérifie que la méthode implementé a quelques nécessite de quelques hipotheses, par exemple le fact qu'on suppose que l’image modèle (charlie) est présente dans l'image cible et qu'elle est suffisamment similaire en termes de taille, orientation et luminosité pour que la corrélation croisée puisse détecter de correspondance.Aussi, on fait l'hypothèse que les niveaux de lumière dans l'image cible et dans l'image modèle sont homogènes. \n",
    "\n",
    "Comme limitation, on a que le charlie template doit être dans la même position dans l'image du marche, c.a.d que la méthode ne supporte pas de rotation. Aussi, l'algoritime est trés lent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTsP-_KBzoHo"
   },
   "source": [
    "## 2.2 Bilateral Filter  \n",
    "\n",
    "On a implémenté notre propre version du filtre bilatéral et on a comparé ses résultats avec ceux de la fonction denoise_bilateral de Scikit-learn.\n",
    "\n",
    " <font color='red' size = '5'> Answer to question a) </font> compare its results vs. scikit ``denoise_bilateral`` function.\n",
    "\n",
    "L'implémentation a permis d'observer les différences de performance et de qualité entre les deux méthodes. Les résultats de notre filtre bilatéral ont montré une capacité à préserver les contours tout en réduisant le bruit. Les paramêtres des deux fonctions sont différents, et donc c'est difficile de regarder des vrais differénces.\n",
    "\n",
    "<font color='red' size = '5'> Answer to question b) </font> Compare and comment the bilateral results versus the mean and gaussian filter for the ``zebra`` group of images of the ``bilateral`` folder\n",
    "\n",
    "Ensuite, on a comparé les résultats du filtre bilatéral avec ceux du filtre moyen et du filtre gaussien sur le groupe d'images de zèbres dans le dossier bilatéral. Les observations ont révélé que le filtre bilatéral était plus efficace pour conserver les détails des contours, tout en removent le bruit de différents types, contrairement au filtre moyen, qui tend à lisser l'image de manière plus uniforme, entraînant une perte de détails. Le filtre gaussien, quant à lui, offrait également un bon lissage, mais avait tendance à créer un flou principalement dans les contours. En résumé, le filtre bilatéral s'est avéré plus adapté pour les images contenant des détails fins tout en maintenant un bon équilibre entre réduction de bruit et préservation des contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poprieté pour comparation\n",
    "def MSE(noisy_image, ref_image):\n",
    "    return np.mean((ref_image - noisy_image)**2)\n",
    "\n",
    "def PSNR(noisy_image, ref_image):\n",
    "    max = np.max(noisy_image)\n",
    "    MSE_ = MSE(noisy_image, ref_image)\n",
    "    PSNR = 20*np.log(max/np.sqrt(MSE_))\n",
    "    return PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FH7TEET0kBg7"
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "\n",
    "#ouvrir les archives de zebra\n",
    "f_bruit = os.path.join(IMDIR, \"bilateral\\zebra\\zebra_speckle_2.png\") #changer le bruit voulu\n",
    "f_ref = os.path.join(IMDIR, \"bilateral\\zebra/ref.jpg\")\n",
    "\n",
    "width=15\n",
    "height=5\n",
    "\n",
    "#lire l'image, convertir et normaliser\n",
    "im = io.imread(f_bruit, as_gray=True)\n",
    "im = im.astype(float)\n",
    "im = normalize(im)\n",
    "\n",
    "im_ref = io.imread(f_ref, as_gray=True) \n",
    "im_ref = im_ref.astype(float)\n",
    "im_ref = normalize(im_ref)\n",
    "\n",
    "#parametres du filtre\n",
    "hs = 3\n",
    "sigma1 = 1\n",
    "sigma2 = 2\n",
    "\n",
    "#notre version du filtre bilateral\n",
    "def bilateral(im, hs, sigma1, sigma2):\n",
    "    bilateral_filter = np.zeros((2*hs+1, 2*hs+1))\n",
    "    grid = np.arange(-hs, hs+1)\n",
    "    u, v = np.meshgrid(grid, grid)\n",
    "    bilateral_filter = np.exp(-(u**2+v**2)/(2*sigma1**2))*np.exp(-(im[u,v]-im[0,0])**2/(2*sigma2**2))\n",
    "    \n",
    "    #normalizer\n",
    "    bilateral_filter = bilateral_filter/np.sum(bilateral_filter)\n",
    "    \n",
    "    return bilateral_filter\n",
    "\n",
    "#création du filtre\n",
    "bilateral_myversion = bilateral(im, hs, sigma1, sigma2) \n",
    "\n",
    "#application du filtre\n",
    "im_filtered_myversion = ndimage.convolve(im, bilateral_myversion)\n",
    "#test pour la deuxiéme itération\n",
    "im_filtered_myversion_2 = ndimage.convolve(im_filtered_myversion, bilateral_myversion)\n",
    "\n",
    "#comparation avec filtre scikit-------------------------------------------------------------------------------\n",
    "#application du filtre scikit\n",
    "im_filtered_scipy = denoise_bilateral(im, win_size=hs*2+1, sigma_color=0.3, sigma_spatial=20)\n",
    "#test pour la deuxiéme itération\n",
    "im_filterd_scipy_2 = denoise_bilateral(im_filtered_scipy, win_size=hs*2+1, sigma_color=0.05, sigma_spatial=15)\n",
    "\n",
    "#comparation avec mean et gaussian filtre-------------------------------------------------------------------------\n",
    "#mean filter\n",
    "kernel = meanKernel(hs)\n",
    "im_filtered_mean = ndimage.convolve(im,kernel)\n",
    "\n",
    "#gaussian filter\n",
    "gaussian = gaussianKernel(hs,sigma, normalize=True)\n",
    "im_filtered_gaussian = ndimage.convolve(im,gaussian)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (width, height))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im_ref, cmap = 'gray')\n",
    "plt.title('ref')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im, cmap = 'gray')\n",
    "plt.title('bruit')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(im_filtered_myversion, cmap = 'gray')\n",
    "plt.title('My_bilateral')\n",
    "plt.show()\n",
    "\n",
    "#test 2 itérations de filtrage -------------------------------------------------------\n",
    "fig = plt.figure(figsize = (width, height))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(im_filtered_myversion_2, cmap = 'gray')\n",
    "plt.title('2 itération My_bilateral')\n",
    "\n",
    "\n",
    "#comparation scikit ----------------------------------------------------------------\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(im_filtered_scipy, cmap = 'gray')\n",
    "plt.title('Bilateral scikit')\n",
    "\n",
    "#comparation mean ----------------------------------------------------------------\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(im_filtered_mean, cmap = 'gray')\n",
    "plt.title('Mean filtre')\n",
    "\n",
    "\n",
    "#comparation gaussian ----------------------------------------------------------------\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(im_filtered_gaussian, cmap = 'gray')\n",
    "plt.title('Gaussian filtre')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#comparation des filtrages pour le valeur de PSNR \n",
    "print(f'PSNR My_bilateral:{PSNR(im_filtered_myversion, im_ref)}\\nPSNR Scipy: {PSNR(im_filtered_scipy, im_ref)} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Nous avons exploré plusieurs approches, notamment le filtre bilatéral, le filtre moyen, le filtre gaussien et les filtres dérivés, ainsi que la corrélation croisée normalisée (NCC) pour la détection d'objets. \n",
    "\n",
    "Nous avons tout d'abord analysé le filtre moyen et le filtre gaussien en appliquant différentes tailles de noyau et valeurs d'écart-type. Les résultats ont révélé que le filtre moyen est efficace pour lisser les images et réduire le bruit, mais il peut également provoquer une perte significative de détails, en particulier dans les zones à contraste élevé. En revanche, le filtre gaussien, avec ses différentes configurations de taille et d'écart-type, a montré une capacité à maintenir une meilleure définition des contours tout en atténuant le bruit. Cependant, un écart-type trop élevé ou une taille de noyau trop grande peuvent entraîner un flou excessif et une perte d'informations critiques.\n",
    "\n",
    "Nous avons ensuite étudié les filtres dérivés, qui sont utilisés pour détecter les gradients dans les images. Ces filtres ont permis d'extraire les contours et les détails des images en mettant en évidence les variations d'intensité. \n",
    "\n",
    "De plus, nous avons implémenté notre propre version du filtre bilatéral, que nous avons comparée à la fonction intégrée denoise_bilateral de Scikit-learn. Nos résultats ont montré que le filtre bilatéral est particulièrement efficace pour réduire le bruit tout en préservant les contours et les détails, contrairement aux filtres moyen et gaussien.\n",
    "\n",
    "Enfin, l'utilisation de la corrélation croisée normalisée (NCC) pour la détection automatique de Waldo (Charlie) a permis de mettre en évidence les hypothèses et les limites de cette méthode. Bien qu'elle soit efficace dans des conditions idéales, des changements de taille et de rotation dans l'image a chercher peuvent compromettre les résultats.\n",
    "\n",
    "Globalement, ces expériences et analyses nous ont permis d'approfondir notre compréhension des techniques de filtrage et de détection d'objets en traitement d'images, tout en soulignant l'importance de choisir les méthodes et les paramètres appropriés pour obtenir des résultats optimaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
